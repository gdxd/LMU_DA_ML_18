{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Higgs Challenge Example using Neural Networks\n",
    "In this part we will look at the **[Higgs Boson ML Challenge](https://www.kaggle.com/c/Higgs-boson)** on Kaggle and attempt a solution using neural networks (NN). The data is available from **[CERN Open Data](http://opendata.cern.ch/record/328)**. More information about the data is available from the links, and in particular at **[Documentation](http://opendata.cern.ch/record/329/files/atlas-higgs-challenge-2014.pdf)**. The general idea is that we want to extract $H\\to\\tau\\tau$ signal from background. In particular, the selection requires one of the taus to decay into an electron or muon and two neutrinos, and the other into hadrons and a neutrino. The challenge is based on Monte Carlo events processed through the **[ATLAS detector](http://atlas.cern/)** simulation and reconstruction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background on Neural Networks\n",
    "(based on lectures from **[ML Course on Coursera](https://www.coursera.org/learn/machine-learning)**)\n",
    "\n",
    "As we saw from the logistic regression yesterday, linear classifiers are often not the best at solving complicated problems. Neural networks introduce nonlinearity. They were originally designed to mimic the brain, and were popular in the 80s and early 90s. Recently they have become popular again, especially as deep neural networks DNNs, including convolutional NNs (CNN), recurrent NNs (RNN), etc. Those are beyond the scope of this class, but we will introduce the basics of NNs.\n",
    "\n",
    "Below is a diagram of a simple NN:\n",
    "![NNFig](https://upload.wikimedia.org/wikipedia/commons/4/46/Colored_neural_network.svg)\n",
    "It is made up of \"neurons\" that get a number of inputs, processes them, and sends the output to other neurons. \n",
    "* Mathematically, one can represent the a neuron's \"activation\" $a = g\\left(\\theta^Tx\\right)$, where $x$ are the inputs (a vector), and $\\theta$ are the parameters (weights) of the model (also a vector), and $g$ is the activation fuction. \n",
    "* For example, if we use a logistic function as the activation function, we can have $g\\left(\\theta^Tx\\right) = \\frac{1}{1+\\mathrm{exp}\\left(-\\theta^Tx\\right)}$, \n",
    "* or if a Rectified Linear Unit (ReLU), $g\\left(\\theta^Tx\\right) = \\mathrm{max}\\left(0, \\theta^Tx\\right)$. \n",
    "* The NN above has an input layer (layer 1), a hidden layer (layer 2), and an output layer (layer 3). One can have more hidden layers. \n",
    "\n",
    "* Let's label the activations of layer 2 as $a_i^{(2)} = g\\left(\\theta_i^{(1)T}x\\right)$, where $i$ is the index of the individual neurons. \n",
    "* Note that the superscript of the $\\theta$ is (1). That is because these are the weights going from layer 1 to 2. Putting together all the individual weight vectors together forms a matrix $\\Theta^{(1)}$.\n",
    "\n",
    "Using matrix notation, we can define $z^{(j)} = \\Theta^{(j-1)}a^{(j-1)}$ and then $a^{(j)} = g(z^{(j)})$. Thus evaluating the NN is a series of matrix multiplications followed by activation functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost function of a NN is similar to what we have for logistic regression, modified to take into account possible multiple outputs, and with more complicated regularization. In order to train the NN, we have to determine the weight matrix $\\Theta$ that minimizes the cost function. Backpropagation is the method used to do that. It calculates the partial derivatives \"errors\" for each $z_i^{(j)}$ by propagating the errors backwards. Usually something like (stochastic) gradient descent is used to solve the problem. For more details on backprorpagation, look, for example, at the **[ML course](https://www.coursera.org/learn/machine-learning)** mentioned above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's start trying to apply a NN to the Higgs Challenge data. We will start using Scikit Learn, and then try **[Keras](https://keras.io/)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the usual setup: \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "df = pd.read_csv('data/atlas-higgs-challenge-2014-v2.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventId</th>\n",
       "      <th>DER_mass_MMC</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>DER_pt_h</th>\n",
       "      <th>DER_deltaeta_jet_jet</th>\n",
       "      <th>DER_mass_jet_jet</th>\n",
       "      <th>DER_prodeta_jet_jet</th>\n",
       "      <th>DER_deltar_tau_lep</th>\n",
       "      <th>DER_pt_tot</th>\n",
       "      <th>...</th>\n",
       "      <th>PRI_jet_leading_eta</th>\n",
       "      <th>PRI_jet_leading_phi</th>\n",
       "      <th>PRI_jet_subleading_pt</th>\n",
       "      <th>PRI_jet_subleading_eta</th>\n",
       "      <th>PRI_jet_subleading_phi</th>\n",
       "      <th>PRI_jet_all_pt</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Label</th>\n",
       "      <th>KaggleSet</th>\n",
       "      <th>KaggleWeight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>138.470</td>\n",
       "      <td>51.655</td>\n",
       "      <td>97.827</td>\n",
       "      <td>27.980</td>\n",
       "      <td>0.91</td>\n",
       "      <td>124.711</td>\n",
       "      <td>2.666</td>\n",
       "      <td>3.064</td>\n",
       "      <td>41.928</td>\n",
       "      <td>...</td>\n",
       "      <td>2.150</td>\n",
       "      <td>0.444</td>\n",
       "      <td>46.062</td>\n",
       "      <td>1.24</td>\n",
       "      <td>-2.475</td>\n",
       "      <td>113.497</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>s</td>\n",
       "      <td>t</td>\n",
       "      <td>0.002653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>160.937</td>\n",
       "      <td>68.768</td>\n",
       "      <td>103.235</td>\n",
       "      <td>48.146</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.473</td>\n",
       "      <td>2.078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725</td>\n",
       "      <td>1.158</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>46.226</td>\n",
       "      <td>0.681042</td>\n",
       "      <td>b</td>\n",
       "      <td>t</td>\n",
       "      <td>2.233584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>162.172</td>\n",
       "      <td>125.953</td>\n",
       "      <td>35.635</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.148</td>\n",
       "      <td>9.336</td>\n",
       "      <td>...</td>\n",
       "      <td>2.053</td>\n",
       "      <td>-2.028</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>44.251</td>\n",
       "      <td>0.715742</td>\n",
       "      <td>b</td>\n",
       "      <td>t</td>\n",
       "      <td>2.347389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100003</td>\n",
       "      <td>143.905</td>\n",
       "      <td>81.417</td>\n",
       "      <td>80.943</td>\n",
       "      <td>0.414</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.310</td>\n",
       "      <td>0.414</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>1.660654</td>\n",
       "      <td>b</td>\n",
       "      <td>t</td>\n",
       "      <td>5.446378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100004</td>\n",
       "      <td>175.864</td>\n",
       "      <td>16.915</td>\n",
       "      <td>134.805</td>\n",
       "      <td>16.405</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.891</td>\n",
       "      <td>16.405</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.904263</td>\n",
       "      <td>b</td>\n",
       "      <td>t</td>\n",
       "      <td>6.245333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EventId  DER_mass_MMC  DER_mass_transverse_met_lep  DER_mass_vis  DER_pt_h  \\\n",
       "0   100000       138.470                       51.655        97.827    27.980   \n",
       "1   100001       160.937                       68.768       103.235    48.146   \n",
       "2   100002      -999.000                      162.172       125.953    35.635   \n",
       "3   100003       143.905                       81.417        80.943     0.414   \n",
       "4   100004       175.864                       16.915       134.805    16.405   \n",
       "\n",
       "   DER_deltaeta_jet_jet  DER_mass_jet_jet  DER_prodeta_jet_jet  \\\n",
       "0                  0.91           124.711                2.666   \n",
       "1               -999.00          -999.000             -999.000   \n",
       "2               -999.00          -999.000             -999.000   \n",
       "3               -999.00          -999.000             -999.000   \n",
       "4               -999.00          -999.000             -999.000   \n",
       "\n",
       "   DER_deltar_tau_lep  DER_pt_tot      ...       PRI_jet_leading_eta  \\\n",
       "0               3.064      41.928      ...                     2.150   \n",
       "1               3.473       2.078      ...                     0.725   \n",
       "2               3.148       9.336      ...                     2.053   \n",
       "3               3.310       0.414      ...                  -999.000   \n",
       "4               3.891      16.405      ...                  -999.000   \n",
       "\n",
       "   PRI_jet_leading_phi  PRI_jet_subleading_pt  PRI_jet_subleading_eta  \\\n",
       "0                0.444                 46.062                    1.24   \n",
       "1                1.158               -999.000                 -999.00   \n",
       "2               -2.028               -999.000                 -999.00   \n",
       "3             -999.000               -999.000                 -999.00   \n",
       "4             -999.000               -999.000                 -999.00   \n",
       "\n",
       "   PRI_jet_subleading_phi  PRI_jet_all_pt    Weight  Label  KaggleSet  \\\n",
       "0                  -2.475         113.497  0.000814      s          t   \n",
       "1                -999.000          46.226  0.681042      b          t   \n",
       "2                -999.000          44.251  0.715742      b          t   \n",
       "3                -999.000          -0.000  1.660654      b          t   \n",
       "4                -999.000           0.000  1.904263      b          t   \n",
       "\n",
       "   KaggleWeight  \n",
       "0      0.002653  \n",
       "1      2.233584  \n",
       "2      2.347389  \n",
       "3      5.446378  \n",
       "4      6.245333  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff81acdeb70>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.PRI_jet_leading_pt[df.PRI_jet_leading_pt>0].hist(bins=50)\n",
    "plt.yscale('log')\n",
    "\n",
    "f=plt.figure()\n",
    "df.DER_mass_MMC[(df.DER_mass_MMC>0)&(df.DER_mass_MMC<250)].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is more information about the variables in the documentation. The variables that start with **DER** are derived quantities, determined by the physicists performing the analysis as variables that discriminate signal from backround. On the other hand, those that start with **PRI** are considered to be primary variables, from which the derived variables are calculated. They themselves generally do not provide much discrimination, but one if the ideas suggested by deep networks is that they can determine the necessary features from the primary variables, potentially even finding variables that the physicists did not consider. *EventId* identifies the event but is not a \"feature.\" The *Weight* is the event weight so that the sum of weights of all signal events should produce the signal yield expected to be observed in 2012, and the sum of weights of all background events should produce the backgroudn yield. Note that the weight varies event to event, because different background and signal processes contribute to the background and signal sets. *Label* indicates if it is a signal or background event. Ignore the *Kaggle* variables--they are only used if you want to reproduce exactly what was used in the Challenge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventId</th>\n",
       "      <th>DER_mass_MMC</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>DER_pt_h</th>\n",
       "      <th>DER_deltaeta_jet_jet</th>\n",
       "      <th>DER_mass_jet_jet</th>\n",
       "      <th>DER_prodeta_jet_jet</th>\n",
       "      <th>DER_deltar_tau_lep</th>\n",
       "      <th>DER_pt_tot</th>\n",
       "      <th>...</th>\n",
       "      <th>PRI_jet_leading_eta</th>\n",
       "      <th>PRI_jet_leading_phi</th>\n",
       "      <th>PRI_jet_subleading_pt</th>\n",
       "      <th>PRI_jet_subleading_eta</th>\n",
       "      <th>PRI_jet_subleading_phi</th>\n",
       "      <th>PRI_jet_all_pt</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Label</th>\n",
       "      <th>KaggleSet</th>\n",
       "      <th>KaggleWeight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>138.470</td>\n",
       "      <td>51.655</td>\n",
       "      <td>97.827</td>\n",
       "      <td>27.980</td>\n",
       "      <td>0.910</td>\n",
       "      <td>124.711</td>\n",
       "      <td>2.666</td>\n",
       "      <td>3.064</td>\n",
       "      <td>41.928</td>\n",
       "      <td>...</td>\n",
       "      <td>2.150</td>\n",
       "      <td>0.444</td>\n",
       "      <td>46.062</td>\n",
       "      <td>1.240</td>\n",
       "      <td>-2.475</td>\n",
       "      <td>113.497</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>0.002653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>160.937</td>\n",
       "      <td>68.768</td>\n",
       "      <td>103.235</td>\n",
       "      <td>48.146</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.473</td>\n",
       "      <td>2.078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725</td>\n",
       "      <td>1.158</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>46.226</td>\n",
       "      <td>0.681042</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>2.233584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>162.172</td>\n",
       "      <td>125.953</td>\n",
       "      <td>35.635</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.148</td>\n",
       "      <td>9.336</td>\n",
       "      <td>...</td>\n",
       "      <td>2.053</td>\n",
       "      <td>-2.028</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>44.251</td>\n",
       "      <td>0.715742</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>2.347389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100003</td>\n",
       "      <td>143.905</td>\n",
       "      <td>81.417</td>\n",
       "      <td>80.943</td>\n",
       "      <td>0.414</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.310</td>\n",
       "      <td>0.414</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>1.660654</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>5.446378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100004</td>\n",
       "      <td>175.864</td>\n",
       "      <td>16.915</td>\n",
       "      <td>134.805</td>\n",
       "      <td>16.405</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.891</td>\n",
       "      <td>16.405</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.904263</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>6.245333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100005</td>\n",
       "      <td>89.744</td>\n",
       "      <td>13.550</td>\n",
       "      <td>59.149</td>\n",
       "      <td>116.344</td>\n",
       "      <td>2.636</td>\n",
       "      <td>284.584</td>\n",
       "      <td>-0.540</td>\n",
       "      <td>1.362</td>\n",
       "      <td>61.619</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.412</td>\n",
       "      <td>-0.653</td>\n",
       "      <td>56.165</td>\n",
       "      <td>0.224</td>\n",
       "      <td>3.106</td>\n",
       "      <td>193.660</td>\n",
       "      <td>0.025434</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>0.083414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100006</td>\n",
       "      <td>148.754</td>\n",
       "      <td>28.862</td>\n",
       "      <td>107.782</td>\n",
       "      <td>106.130</td>\n",
       "      <td>0.733</td>\n",
       "      <td>158.359</td>\n",
       "      <td>0.113</td>\n",
       "      <td>2.941</td>\n",
       "      <td>2.545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864</td>\n",
       "      <td>1.450</td>\n",
       "      <td>56.867</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-2.767</td>\n",
       "      <td>179.877</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>0.002653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100007</td>\n",
       "      <td>154.916</td>\n",
       "      <td>10.418</td>\n",
       "      <td>94.714</td>\n",
       "      <td>29.169</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.897</td>\n",
       "      <td>1.526</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.715</td>\n",
       "      <td>-1.724</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>30.638</td>\n",
       "      <td>0.005721</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>0.018636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100008</td>\n",
       "      <td>105.594</td>\n",
       "      <td>50.559</td>\n",
       "      <td>100.989</td>\n",
       "      <td>4.288</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.904</td>\n",
       "      <td>4.288</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.614803</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>5.296003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100009</td>\n",
       "      <td>128.053</td>\n",
       "      <td>88.941</td>\n",
       "      <td>69.272</td>\n",
       "      <td>193.392</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>1.609</td>\n",
       "      <td>28.859</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.767</td>\n",
       "      <td>-2.514</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>167.735</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>0.001502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100010</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>86.240</td>\n",
       "      <td>79.692</td>\n",
       "      <td>27.201</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.338</td>\n",
       "      <td>27.201</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.701141</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>2.299504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100011</td>\n",
       "      <td>114.744</td>\n",
       "      <td>10.286</td>\n",
       "      <td>75.712</td>\n",
       "      <td>30.816</td>\n",
       "      <td>2.563</td>\n",
       "      <td>252.599</td>\n",
       "      <td>-1.401</td>\n",
       "      <td>2.888</td>\n",
       "      <td>36.745</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.790</td>\n",
       "      <td>0.303</td>\n",
       "      <td>56.876</td>\n",
       "      <td>1.773</td>\n",
       "      <td>-2.079</td>\n",
       "      <td>165.640</td>\n",
       "      <td>0.093659</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>0.307170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100012</td>\n",
       "      <td>145.297</td>\n",
       "      <td>64.234</td>\n",
       "      <td>103.565</td>\n",
       "      <td>106.999</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.183</td>\n",
       "      <td>24.660</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.970</td>\n",
       "      <td>1.943</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>93.117</td>\n",
       "      <td>0.512740</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>1.681611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100013</td>\n",
       "      <td>82.488</td>\n",
       "      <td>31.663</td>\n",
       "      <td>64.128</td>\n",
       "      <td>8.232</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.823</td>\n",
       "      <td>8.232</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.665890</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>2.183892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100014</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>109.412</td>\n",
       "      <td>14.398</td>\n",
       "      <td>17.323</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.472</td>\n",
       "      <td>17.323</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.655922</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>2.151199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100015</td>\n",
       "      <td>111.026</td>\n",
       "      <td>32.096</td>\n",
       "      <td>75.271</td>\n",
       "      <td>23.067</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.205</td>\n",
       "      <td>23.067</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.005721</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>0.018636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100016</td>\n",
       "      <td>114.256</td>\n",
       "      <td>4.351</td>\n",
       "      <td>67.963</td>\n",
       "      <td>47.221</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.954</td>\n",
       "      <td>26.243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.766</td>\n",
       "      <td>-0.686</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>36.263</td>\n",
       "      <td>0.443598</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>1.454848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100017</td>\n",
       "      <td>127.861</td>\n",
       "      <td>50.953</td>\n",
       "      <td>77.267</td>\n",
       "      <td>26.967</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.833</td>\n",
       "      <td>26.967</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>0.001503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100018</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>85.186</td>\n",
       "      <td>68.827</td>\n",
       "      <td>5.042</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.116</td>\n",
       "      <td>5.042</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.561633</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>5.121624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100019</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>88.767</td>\n",
       "      <td>115.058</td>\n",
       "      <td>15.337</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.879</td>\n",
       "      <td>15.337</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>1.823163</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>5.979351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>100020</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>89.705</td>\n",
       "      <td>41.765</td>\n",
       "      <td>18.437</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>1.395</td>\n",
       "      <td>18.437</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.670373</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>2.198594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>100021</td>\n",
       "      <td>90.736</td>\n",
       "      <td>18.674</td>\n",
       "      <td>60.231</td>\n",
       "      <td>25.156</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.363</td>\n",
       "      <td>25.156</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.512740</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>1.681611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>100022</td>\n",
       "      <td>87.075</td>\n",
       "      <td>38.217</td>\n",
       "      <td>67.041</td>\n",
       "      <td>2.347</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.852</td>\n",
       "      <td>2.347</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.393245</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>4.569368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>100023</td>\n",
       "      <td>141.481</td>\n",
       "      <td>0.736</td>\n",
       "      <td>111.581</td>\n",
       "      <td>174.075</td>\n",
       "      <td>1.955</td>\n",
       "      <td>364.344</td>\n",
       "      <td>-0.923</td>\n",
       "      <td>1.335</td>\n",
       "      <td>6.663</td>\n",
       "      <td>...</td>\n",
       "      <td>1.156</td>\n",
       "      <td>1.416</td>\n",
       "      <td>82.477</td>\n",
       "      <td>-0.798</td>\n",
       "      <td>-2.785</td>\n",
       "      <td>278.009</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>0.001503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>100024</td>\n",
       "      <td>110.785</td>\n",
       "      <td>72.927</td>\n",
       "      <td>82.775</td>\n",
       "      <td>30.888</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.032</td>\n",
       "      <td>30.888</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.774979</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>2.541666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>100025</td>\n",
       "      <td>76.883</td>\n",
       "      <td>34.384</td>\n",
       "      <td>56.993</td>\n",
       "      <td>5.569</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.912</td>\n",
       "      <td>5.569</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.512740</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>1.681611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>100026</td>\n",
       "      <td>137.197</td>\n",
       "      <td>68.009</td>\n",
       "      <td>78.296</td>\n",
       "      <td>35.332</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.883</td>\n",
       "      <td>0.204</td>\n",
       "      <td>...</td>\n",
       "      <td>4.347</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>35.527</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>0.001503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>100027</td>\n",
       "      <td>111.271</td>\n",
       "      <td>27.180</td>\n",
       "      <td>70.642</td>\n",
       "      <td>144.766</td>\n",
       "      <td>4.936</td>\n",
       "      <td>1021.322</td>\n",
       "      <td>-5.834</td>\n",
       "      <td>1.795</td>\n",
       "      <td>0.367</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.961</td>\n",
       "      <td>2.220</td>\n",
       "      <td>43.458</td>\n",
       "      <td>2.974</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>214.170</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>0.001503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>100028</td>\n",
       "      <td>118.104</td>\n",
       "      <td>2.633</td>\n",
       "      <td>77.310</td>\n",
       "      <td>91.388</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>1.976</td>\n",
       "      <td>21.536</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>1.426</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>77.221</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>0.001503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>100029</td>\n",
       "      <td>98.761</td>\n",
       "      <td>14.024</td>\n",
       "      <td>74.230</td>\n",
       "      <td>132.806</td>\n",
       "      <td>3.676</td>\n",
       "      <td>315.854</td>\n",
       "      <td>-2.665</td>\n",
       "      <td>1.261</td>\n",
       "      <td>23.290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993</td>\n",
       "      <td>-2.018</td>\n",
       "      <td>32.625</td>\n",
       "      <td>-2.683</td>\n",
       "      <td>-1.467</td>\n",
       "      <td>113.252</td>\n",
       "      <td>0.094460</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>0.309795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818208</th>\n",
       "      <td>918208</td>\n",
       "      <td>201.622</td>\n",
       "      <td>38.204</td>\n",
       "      <td>131.375</td>\n",
       "      <td>1.017</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>4.455</td>\n",
       "      <td>1.017</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.925626</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>41.468615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818209</th>\n",
       "      <td>918209</td>\n",
       "      <td>101.034</td>\n",
       "      <td>58.485</td>\n",
       "      <td>80.316</td>\n",
       "      <td>0.149</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.724</td>\n",
       "      <td>0.149</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.385835</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>62.086275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818210</th>\n",
       "      <td>918210</td>\n",
       "      <td>136.095</td>\n",
       "      <td>49.715</td>\n",
       "      <td>102.729</td>\n",
       "      <td>6.810</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.069</td>\n",
       "      <td>6.810</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005721</td>\n",
       "      <td>1</td>\n",
       "      <td>u</td>\n",
       "      <td>0.259892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818211</th>\n",
       "      <td>918211</td>\n",
       "      <td>80.222</td>\n",
       "      <td>5.694</td>\n",
       "      <td>57.055</td>\n",
       "      <td>38.959</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.269</td>\n",
       "      <td>2.985</td>\n",
       "      <td>...</td>\n",
       "      <td>2.713</td>\n",
       "      <td>1.790</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>37.489</td>\n",
       "      <td>0.512740</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>22.971060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818212</th>\n",
       "      <td>918212</td>\n",
       "      <td>143.655</td>\n",
       "      <td>106.016</td>\n",
       "      <td>113.078</td>\n",
       "      <td>13.279</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.497</td>\n",
       "      <td>50.204</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.867</td>\n",
       "      <td>2.433</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>52.332</td>\n",
       "      <td>0.226870</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>10.163918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818213</th>\n",
       "      <td>918213</td>\n",
       "      <td>225.431</td>\n",
       "      <td>94.018</td>\n",
       "      <td>135.646</td>\n",
       "      <td>0.123</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.594</td>\n",
       "      <td>0.123</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.909680</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>40.754236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818214</th>\n",
       "      <td>918214</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>85.725</td>\n",
       "      <td>164.017</td>\n",
       "      <td>150.189</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.105</td>\n",
       "      <td>24.241</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.333</td>\n",
       "      <td>-1.977</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>126.319</td>\n",
       "      <td>0.782818</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>35.070702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818215</th>\n",
       "      <td>918215</td>\n",
       "      <td>93.050</td>\n",
       "      <td>21.326</td>\n",
       "      <td>68.026</td>\n",
       "      <td>3.505</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.767</td>\n",
       "      <td>3.505</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005721</td>\n",
       "      <td>1</td>\n",
       "      <td>u</td>\n",
       "      <td>0.259892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818216</th>\n",
       "      <td>918216</td>\n",
       "      <td>24.995</td>\n",
       "      <td>35.732</td>\n",
       "      <td>20.797</td>\n",
       "      <td>51.803</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.699</td>\n",
       "      <td>51.803</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.636427</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>28.512309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818217</th>\n",
       "      <td>918217</td>\n",
       "      <td>151.604</td>\n",
       "      <td>21.734</td>\n",
       "      <td>105.448</td>\n",
       "      <td>87.754</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.580</td>\n",
       "      <td>47.695</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.565</td>\n",
       "      <td>0.111</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>48.125</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>1</td>\n",
       "      <td>u</td>\n",
       "      <td>0.020956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818218</th>\n",
       "      <td>918218</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>52.874</td>\n",
       "      <td>99.112</td>\n",
       "      <td>26.951</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.925</td>\n",
       "      <td>26.951</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.611755</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>27.407016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818219</th>\n",
       "      <td>918219</td>\n",
       "      <td>77.364</td>\n",
       "      <td>33.974</td>\n",
       "      <td>60.653</td>\n",
       "      <td>0.636</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.746</td>\n",
       "      <td>0.636</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.512740</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>22.971060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818220</th>\n",
       "      <td>918220</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>77.513</td>\n",
       "      <td>36.229</td>\n",
       "      <td>1.756</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>1.098</td>\n",
       "      <td>1.756</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.562147</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>25.184532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818221</th>\n",
       "      <td>918221</td>\n",
       "      <td>101.483</td>\n",
       "      <td>12.234</td>\n",
       "      <td>63.279</td>\n",
       "      <td>144.481</td>\n",
       "      <td>5.222</td>\n",
       "      <td>913.469</td>\n",
       "      <td>-6.675</td>\n",
       "      <td>1.325</td>\n",
       "      <td>5.282</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.990</td>\n",
       "      <td>1.491</td>\n",
       "      <td>50.791</td>\n",
       "      <td>2.233</td>\n",
       "      <td>1.287</td>\n",
       "      <td>140.280</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>1</td>\n",
       "      <td>u</td>\n",
       "      <td>0.020956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818222</th>\n",
       "      <td>918222</td>\n",
       "      <td>106.082</td>\n",
       "      <td>17.146</td>\n",
       "      <td>60.347</td>\n",
       "      <td>252.677</td>\n",
       "      <td>3.899</td>\n",
       "      <td>709.003</td>\n",
       "      <td>-3.596</td>\n",
       "      <td>0.880</td>\n",
       "      <td>4.530</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.401</td>\n",
       "      <td>-2.440</td>\n",
       "      <td>53.867</td>\n",
       "      <td>1.498</td>\n",
       "      <td>-2.218</td>\n",
       "      <td>250.408</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>1</td>\n",
       "      <td>u</td>\n",
       "      <td>0.020956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818223</th>\n",
       "      <td>918223</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>130.745</td>\n",
       "      <td>305.346</td>\n",
       "      <td>248.884</td>\n",
       "      <td>1.069</td>\n",
       "      <td>217.075</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>3.597</td>\n",
       "      <td>44.572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.566</td>\n",
       "      <td>-0.357</td>\n",
       "      <td>114.553</td>\n",
       "      <td>-0.504</td>\n",
       "      <td>0.832</td>\n",
       "      <td>369.304</td>\n",
       "      <td>0.226870</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>10.163918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818224</th>\n",
       "      <td>918224</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>89.909</td>\n",
       "      <td>48.149</td>\n",
       "      <td>52.696</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>1.319</td>\n",
       "      <td>58.852</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.714</td>\n",
       "      <td>-1.626</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>37.855</td>\n",
       "      <td>0.633648</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>28.387819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818225</th>\n",
       "      <td>918225</td>\n",
       "      <td>75.931</td>\n",
       "      <td>31.815</td>\n",
       "      <td>51.415</td>\n",
       "      <td>19.630</td>\n",
       "      <td>2.057</td>\n",
       "      <td>140.906</td>\n",
       "      <td>4.077</td>\n",
       "      <td>2.968</td>\n",
       "      <td>44.036</td>\n",
       "      <td>...</td>\n",
       "      <td>3.294</td>\n",
       "      <td>-0.783</td>\n",
       "      <td>37.409</td>\n",
       "      <td>1.238</td>\n",
       "      <td>1.868</td>\n",
       "      <td>90.118</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>1</td>\n",
       "      <td>u</td>\n",
       "      <td>0.037002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818226</th>\n",
       "      <td>918226</td>\n",
       "      <td>140.804</td>\n",
       "      <td>24.712</td>\n",
       "      <td>98.037</td>\n",
       "      <td>29.817</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.907</td>\n",
       "      <td>21.578</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>38.654</td>\n",
       "      <td>0.005721</td>\n",
       "      <td>1</td>\n",
       "      <td>u</td>\n",
       "      <td>0.259892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818227</th>\n",
       "      <td>918227</td>\n",
       "      <td>96.816</td>\n",
       "      <td>19.198</td>\n",
       "      <td>45.972</td>\n",
       "      <td>240.285</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>1.130</td>\n",
       "      <td>30.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.438</td>\n",
       "      <td>2.462</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>210.299</td>\n",
       "      <td>0.005721</td>\n",
       "      <td>1</td>\n",
       "      <td>u</td>\n",
       "      <td>0.259892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818228</th>\n",
       "      <td>918228</td>\n",
       "      <td>73.840</td>\n",
       "      <td>60.332</td>\n",
       "      <td>66.765</td>\n",
       "      <td>1.454</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.377</td>\n",
       "      <td>1.454</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.433869</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>64.238228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818229</th>\n",
       "      <td>918229</td>\n",
       "      <td>161.338</td>\n",
       "      <td>82.848</td>\n",
       "      <td>101.681</td>\n",
       "      <td>76.665</td>\n",
       "      <td>2.882</td>\n",
       "      <td>273.808</td>\n",
       "      <td>-0.343</td>\n",
       "      <td>3.075</td>\n",
       "      <td>18.813</td>\n",
       "      <td>...</td>\n",
       "      <td>2.758</td>\n",
       "      <td>1.131</td>\n",
       "      <td>37.876</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>-1.672</td>\n",
       "      <td>136.986</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>1</td>\n",
       "      <td>u</td>\n",
       "      <td>0.020956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818230</th>\n",
       "      <td>918230</td>\n",
       "      <td>81.272</td>\n",
       "      <td>77.396</td>\n",
       "      <td>57.820</td>\n",
       "      <td>138.807</td>\n",
       "      <td>2.405</td>\n",
       "      <td>349.248</td>\n",
       "      <td>-1.413</td>\n",
       "      <td>1.162</td>\n",
       "      <td>90.604</td>\n",
       "      <td>...</td>\n",
       "      <td>1.021</td>\n",
       "      <td>-1.313</td>\n",
       "      <td>53.388</td>\n",
       "      <td>-1.384</td>\n",
       "      <td>2.747</td>\n",
       "      <td>320.076</td>\n",
       "      <td>0.301427</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>13.504126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818231</th>\n",
       "      <td>918231</td>\n",
       "      <td>110.083</td>\n",
       "      <td>24.084</td>\n",
       "      <td>68.991</td>\n",
       "      <td>105.747</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>1.840</td>\n",
       "      <td>9.618</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.348</td>\n",
       "      <td>-2.836</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>110.841</td>\n",
       "      <td>0.019533</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>0.875080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818232</th>\n",
       "      <td>918232</td>\n",
       "      <td>119.012</td>\n",
       "      <td>75.869</td>\n",
       "      <td>83.754</td>\n",
       "      <td>2.956</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.734</td>\n",
       "      <td>2.956</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>1.433121</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>64.204716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818233</th>\n",
       "      <td>918233</td>\n",
       "      <td>105.668</td>\n",
       "      <td>46.443</td>\n",
       "      <td>60.048</td>\n",
       "      <td>156.191</td>\n",
       "      <td>0.403</td>\n",
       "      <td>47.746</td>\n",
       "      <td>0.936</td>\n",
       "      <td>1.279</td>\n",
       "      <td>6.133</td>\n",
       "      <td>...</td>\n",
       "      <td>1.190</td>\n",
       "      <td>-0.766</td>\n",
       "      <td>41.791</td>\n",
       "      <td>0.787</td>\n",
       "      <td>-1.090</td>\n",
       "      <td>154.056</td>\n",
       "      <td>0.005721</td>\n",
       "      <td>1</td>\n",
       "      <td>u</td>\n",
       "      <td>0.259892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818234</th>\n",
       "      <td>918234</td>\n",
       "      <td>99.294</td>\n",
       "      <td>30.097</td>\n",
       "      <td>62.713</td>\n",
       "      <td>65.861</td>\n",
       "      <td>3.312</td>\n",
       "      <td>471.319</td>\n",
       "      <td>-2.611</td>\n",
       "      <td>2.294</td>\n",
       "      <td>2.889</td>\n",
       "      <td>...</td>\n",
       "      <td>1.293</td>\n",
       "      <td>-0.868</td>\n",
       "      <td>70.158</td>\n",
       "      <td>-2.018</td>\n",
       "      <td>2.893</td>\n",
       "      <td>178.856</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>1</td>\n",
       "      <td>u</td>\n",
       "      <td>0.020956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818235</th>\n",
       "      <td>918235</td>\n",
       "      <td>108.497</td>\n",
       "      <td>9.837</td>\n",
       "      <td>65.149</td>\n",
       "      <td>18.006</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.742</td>\n",
       "      <td>18.006</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>1.189365</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>53.284258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818236</th>\n",
       "      <td>918236</td>\n",
       "      <td>96.711</td>\n",
       "      <td>20.006</td>\n",
       "      <td>66.942</td>\n",
       "      <td>29.761</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.479</td>\n",
       "      <td>2.739</td>\n",
       "      <td>...</td>\n",
       "      <td>1.460</td>\n",
       "      <td>2.637</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>30.863</td>\n",
       "      <td>0.512740</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>22.971060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818237</th>\n",
       "      <td>918237</td>\n",
       "      <td>92.373</td>\n",
       "      <td>80.109</td>\n",
       "      <td>77.619</td>\n",
       "      <td>3.984</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.486</td>\n",
       "      <td>3.984</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>1.531213</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>68.599269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>818238 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        EventId  DER_mass_MMC  DER_mass_transverse_met_lep  DER_mass_vis  \\\n",
       "0        100000       138.470                       51.655        97.827   \n",
       "1        100001       160.937                       68.768       103.235   \n",
       "2        100002      -999.000                      162.172       125.953   \n",
       "3        100003       143.905                       81.417        80.943   \n",
       "4        100004       175.864                       16.915       134.805   \n",
       "5        100005        89.744                       13.550        59.149   \n",
       "6        100006       148.754                       28.862       107.782   \n",
       "7        100007       154.916                       10.418        94.714   \n",
       "8        100008       105.594                       50.559       100.989   \n",
       "9        100009       128.053                       88.941        69.272   \n",
       "10       100010      -999.000                       86.240        79.692   \n",
       "11       100011       114.744                       10.286        75.712   \n",
       "12       100012       145.297                       64.234       103.565   \n",
       "13       100013        82.488                       31.663        64.128   \n",
       "14       100014      -999.000                      109.412        14.398   \n",
       "15       100015       111.026                       32.096        75.271   \n",
       "16       100016       114.256                        4.351        67.963   \n",
       "17       100017       127.861                       50.953        77.267   \n",
       "18       100018      -999.000                       85.186        68.827   \n",
       "19       100019      -999.000                       88.767       115.058   \n",
       "20       100020      -999.000                       89.705        41.765   \n",
       "21       100021        90.736                       18.674        60.231   \n",
       "22       100022        87.075                       38.217        67.041   \n",
       "23       100023       141.481                        0.736       111.581   \n",
       "24       100024       110.785                       72.927        82.775   \n",
       "25       100025        76.883                       34.384        56.993   \n",
       "26       100026       137.197                       68.009        78.296   \n",
       "27       100027       111.271                       27.180        70.642   \n",
       "28       100028       118.104                        2.633        77.310   \n",
       "29       100029        98.761                       14.024        74.230   \n",
       "...         ...           ...                          ...           ...   \n",
       "818208   918208       201.622                       38.204       131.375   \n",
       "818209   918209       101.034                       58.485        80.316   \n",
       "818210   918210       136.095                       49.715       102.729   \n",
       "818211   918211        80.222                        5.694        57.055   \n",
       "818212   918212       143.655                      106.016       113.078   \n",
       "818213   918213       225.431                       94.018       135.646   \n",
       "818214   918214      -999.000                       85.725       164.017   \n",
       "818215   918215        93.050                       21.326        68.026   \n",
       "818216   918216        24.995                       35.732        20.797   \n",
       "818217   918217       151.604                       21.734       105.448   \n",
       "818218   918218      -999.000                       52.874        99.112   \n",
       "818219   918219        77.364                       33.974        60.653   \n",
       "818220   918220      -999.000                       77.513        36.229   \n",
       "818221   918221       101.483                       12.234        63.279   \n",
       "818222   918222       106.082                       17.146        60.347   \n",
       "818223   918223      -999.000                      130.745       305.346   \n",
       "818224   918224      -999.000                       89.909        48.149   \n",
       "818225   918225        75.931                       31.815        51.415   \n",
       "818226   918226       140.804                       24.712        98.037   \n",
       "818227   918227        96.816                       19.198        45.972   \n",
       "818228   918228        73.840                       60.332        66.765   \n",
       "818229   918229       161.338                       82.848       101.681   \n",
       "818230   918230        81.272                       77.396        57.820   \n",
       "818231   918231       110.083                       24.084        68.991   \n",
       "818232   918232       119.012                       75.869        83.754   \n",
       "818233   918233       105.668                       46.443        60.048   \n",
       "818234   918234        99.294                       30.097        62.713   \n",
       "818235   918235       108.497                        9.837        65.149   \n",
       "818236   918236        96.711                       20.006        66.942   \n",
       "818237   918237        92.373                       80.109        77.619   \n",
       "\n",
       "        DER_pt_h  DER_deltaeta_jet_jet  DER_mass_jet_jet  DER_prodeta_jet_jet  \\\n",
       "0         27.980                 0.910           124.711                2.666   \n",
       "1         48.146              -999.000          -999.000             -999.000   \n",
       "2         35.635              -999.000          -999.000             -999.000   \n",
       "3          0.414              -999.000          -999.000             -999.000   \n",
       "4         16.405              -999.000          -999.000             -999.000   \n",
       "5        116.344                 2.636           284.584               -0.540   \n",
       "6        106.130                 0.733           158.359                0.113   \n",
       "7         29.169              -999.000          -999.000             -999.000   \n",
       "8          4.288              -999.000          -999.000             -999.000   \n",
       "9        193.392              -999.000          -999.000             -999.000   \n",
       "10        27.201              -999.000          -999.000             -999.000   \n",
       "11        30.816                 2.563           252.599               -1.401   \n",
       "12       106.999              -999.000          -999.000             -999.000   \n",
       "13         8.232              -999.000          -999.000             -999.000   \n",
       "14        17.323              -999.000          -999.000             -999.000   \n",
       "15        23.067              -999.000          -999.000             -999.000   \n",
       "16        47.221              -999.000          -999.000             -999.000   \n",
       "17        26.967              -999.000          -999.000             -999.000   \n",
       "18         5.042              -999.000          -999.000             -999.000   \n",
       "19        15.337              -999.000          -999.000             -999.000   \n",
       "20        18.437              -999.000          -999.000             -999.000   \n",
       "21        25.156              -999.000          -999.000             -999.000   \n",
       "22         2.347              -999.000          -999.000             -999.000   \n",
       "23       174.075                 1.955           364.344               -0.923   \n",
       "24        30.888              -999.000          -999.000             -999.000   \n",
       "25         5.569              -999.000          -999.000             -999.000   \n",
       "26        35.332              -999.000          -999.000             -999.000   \n",
       "27       144.766                 4.936          1021.322               -5.834   \n",
       "28        91.388              -999.000          -999.000             -999.000   \n",
       "29       132.806                 3.676           315.854               -2.665   \n",
       "...          ...                   ...               ...                  ...   \n",
       "818208     1.017              -999.000          -999.000             -999.000   \n",
       "818209     0.149              -999.000          -999.000             -999.000   \n",
       "818210     6.810              -999.000          -999.000             -999.000   \n",
       "818211    38.959              -999.000          -999.000             -999.000   \n",
       "818212    13.279              -999.000          -999.000             -999.000   \n",
       "818213     0.123              -999.000          -999.000             -999.000   \n",
       "818214   150.189              -999.000          -999.000             -999.000   \n",
       "818215     3.505              -999.000          -999.000             -999.000   \n",
       "818216    51.803              -999.000          -999.000             -999.000   \n",
       "818217    87.754              -999.000          -999.000             -999.000   \n",
       "818218    26.951              -999.000          -999.000             -999.000   \n",
       "818219     0.636              -999.000          -999.000             -999.000   \n",
       "818220     1.756              -999.000          -999.000             -999.000   \n",
       "818221   144.481                 5.222           913.469               -6.675   \n",
       "818222   252.677                 3.899           709.003               -3.596   \n",
       "818223   248.884                 1.069           217.075               -0.285   \n",
       "818224    52.696              -999.000          -999.000             -999.000   \n",
       "818225    19.630                 2.057           140.906                4.077   \n",
       "818226    29.817              -999.000          -999.000             -999.000   \n",
       "818227   240.285              -999.000          -999.000             -999.000   \n",
       "818228     1.454              -999.000          -999.000             -999.000   \n",
       "818229    76.665                 2.882           273.808               -0.343   \n",
       "818230   138.807                 2.405           349.248               -1.413   \n",
       "818231   105.747              -999.000          -999.000             -999.000   \n",
       "818232     2.956              -999.000          -999.000             -999.000   \n",
       "818233   156.191                 0.403            47.746                0.936   \n",
       "818234    65.861                 3.312           471.319               -2.611   \n",
       "818235    18.006              -999.000          -999.000             -999.000   \n",
       "818236    29.761              -999.000          -999.000             -999.000   \n",
       "818237     3.984              -999.000          -999.000             -999.000   \n",
       "\n",
       "        DER_deltar_tau_lep  DER_pt_tot      ...       PRI_jet_leading_eta  \\\n",
       "0                    3.064      41.928      ...                     2.150   \n",
       "1                    3.473       2.078      ...                     0.725   \n",
       "2                    3.148       9.336      ...                     2.053   \n",
       "3                    3.310       0.414      ...                  -999.000   \n",
       "4                    3.891      16.405      ...                  -999.000   \n",
       "5                    1.362      61.619      ...                    -2.412   \n",
       "6                    2.941       2.545      ...                     0.864   \n",
       "7                    2.897       1.526      ...                    -0.715   \n",
       "8                    2.904       4.288      ...                  -999.000   \n",
       "9                    1.609      28.859      ...                    -2.767   \n",
       "10                   2.338      27.201      ...                  -999.000   \n",
       "11                   2.888      36.745      ...                    -0.790   \n",
       "12                   2.183      24.660      ...                    -0.970   \n",
       "13                   2.823       8.232      ...                  -999.000   \n",
       "14                   0.472      17.323      ...                  -999.000   \n",
       "15                   3.205      23.067      ...                  -999.000   \n",
       "16                   2.954      26.243      ...                    -0.766   \n",
       "17                   2.833      26.967      ...                  -999.000   \n",
       "18                   2.116       5.042      ...                  -999.000   \n",
       "19                   2.879      15.337      ...                  -999.000   \n",
       "20                   1.395      18.437      ...                  -999.000   \n",
       "21                   2.363      25.156      ...                  -999.000   \n",
       "22                   2.852       2.347      ...                  -999.000   \n",
       "23                   1.335       6.663      ...                     1.156   \n",
       "24                   3.032      30.888      ...                  -999.000   \n",
       "25                   2.912       5.569      ...                  -999.000   \n",
       "26                   2.883       0.204      ...                     4.347   \n",
       "27                   1.795       0.367      ...                    -1.961   \n",
       "28                   1.976      21.536      ...                    -0.049   \n",
       "29                   1.261      23.290      ...                     0.993   \n",
       "...                    ...         ...      ...                       ...   \n",
       "818208               4.455       1.017      ...                  -999.000   \n",
       "818209               2.724       0.149      ...                  -999.000   \n",
       "818210               3.069       6.810      ...                  -999.000   \n",
       "818211               2.269       2.985      ...                     2.713   \n",
       "818212               2.497      50.204      ...                    -1.867   \n",
       "818213               3.594       0.123      ...                  -999.000   \n",
       "818214               3.105      24.241      ...                    -0.333   \n",
       "818215               2.767       3.505      ...                  -999.000   \n",
       "818216               0.699      51.803      ...                  -999.000   \n",
       "818217               2.580      47.695      ...                    -3.565   \n",
       "818218               2.925      26.951      ...                  -999.000   \n",
       "818219               2.746       0.636      ...                  -999.000   \n",
       "818220               1.098       1.756      ...                  -999.000   \n",
       "818221               1.325       5.282      ...                    -2.990   \n",
       "818222               0.880       4.530      ...                    -2.401   \n",
       "818223               3.597      44.572      ...                     0.566   \n",
       "818224               1.319      58.852      ...                    -0.714   \n",
       "818225               2.968      44.036      ...                     3.294   \n",
       "818226               2.907      21.578      ...                    -0.153   \n",
       "818227               1.130      30.000      ...                    -1.438   \n",
       "818228               2.377       1.454      ...                  -999.000   \n",
       "818229               3.075      18.813      ...                     2.758   \n",
       "818230               1.162      90.604      ...                     1.021   \n",
       "818231               1.840       9.618      ...                    -0.348   \n",
       "818232               2.734       2.956      ...                  -999.000   \n",
       "818233               1.279       6.133      ...                     1.190   \n",
       "818234               2.294       2.889      ...                     1.293   \n",
       "818235               2.742      18.006      ...                  -999.000   \n",
       "818236               2.479       2.739      ...                     1.460   \n",
       "818237               2.486       3.984      ...                  -999.000   \n",
       "\n",
       "        PRI_jet_leading_phi  PRI_jet_subleading_pt  PRI_jet_subleading_eta  \\\n",
       "0                     0.444                 46.062                   1.240   \n",
       "1                     1.158               -999.000                -999.000   \n",
       "2                    -2.028               -999.000                -999.000   \n",
       "3                  -999.000               -999.000                -999.000   \n",
       "4                  -999.000               -999.000                -999.000   \n",
       "5                    -0.653                 56.165                   0.224   \n",
       "6                     1.450                 56.867                   0.131   \n",
       "7                    -1.724               -999.000                -999.000   \n",
       "8                  -999.000               -999.000                -999.000   \n",
       "9                    -2.514               -999.000                -999.000   \n",
       "10                 -999.000               -999.000                -999.000   \n",
       "11                    0.303                 56.876                   1.773   \n",
       "12                    1.943               -999.000                -999.000   \n",
       "13                 -999.000               -999.000                -999.000   \n",
       "14                 -999.000               -999.000                -999.000   \n",
       "15                 -999.000               -999.000                -999.000   \n",
       "16                   -0.686               -999.000                -999.000   \n",
       "17                 -999.000               -999.000                -999.000   \n",
       "18                 -999.000               -999.000                -999.000   \n",
       "19                 -999.000               -999.000                -999.000   \n",
       "20                 -999.000               -999.000                -999.000   \n",
       "21                 -999.000               -999.000                -999.000   \n",
       "22                 -999.000               -999.000                -999.000   \n",
       "23                    1.416                 82.477                  -0.798   \n",
       "24                 -999.000               -999.000                -999.000   \n",
       "25                 -999.000               -999.000                -999.000   \n",
       "26                   -0.169               -999.000                -999.000   \n",
       "27                    2.220                 43.458                   2.974   \n",
       "28                    1.426               -999.000                -999.000   \n",
       "29                   -2.018                 32.625                  -2.683   \n",
       "...                     ...                    ...                     ...   \n",
       "818208             -999.000               -999.000                -999.000   \n",
       "818209             -999.000               -999.000                -999.000   \n",
       "818210             -999.000               -999.000                -999.000   \n",
       "818211                1.790               -999.000                -999.000   \n",
       "818212                2.433               -999.000                -999.000   \n",
       "818213             -999.000               -999.000                -999.000   \n",
       "818214               -1.977               -999.000                -999.000   \n",
       "818215             -999.000               -999.000                -999.000   \n",
       "818216             -999.000               -999.000                -999.000   \n",
       "818217                0.111               -999.000                -999.000   \n",
       "818218             -999.000               -999.000                -999.000   \n",
       "818219             -999.000               -999.000                -999.000   \n",
       "818220             -999.000               -999.000                -999.000   \n",
       "818221                1.491                 50.791                   2.233   \n",
       "818222               -2.440                 53.867                   1.498   \n",
       "818223               -0.357                114.553                  -0.504   \n",
       "818224               -1.626               -999.000                -999.000   \n",
       "818225               -0.783                 37.409                   1.238   \n",
       "818226               -0.147               -999.000                -999.000   \n",
       "818227                2.462               -999.000                -999.000   \n",
       "818228             -999.000               -999.000                -999.000   \n",
       "818229                1.131                 37.876                  -0.124   \n",
       "818230               -1.313                 53.388                  -1.384   \n",
       "818231               -2.836               -999.000                -999.000   \n",
       "818232             -999.000               -999.000                -999.000   \n",
       "818233               -0.766                 41.791                   0.787   \n",
       "818234               -0.868                 70.158                  -2.018   \n",
       "818235             -999.000               -999.000                -999.000   \n",
       "818236                2.637               -999.000                -999.000   \n",
       "818237             -999.000               -999.000                -999.000   \n",
       "\n",
       "        PRI_jet_subleading_phi  PRI_jet_all_pt    Weight  Label  KaggleSet  \\\n",
       "0                       -2.475         113.497  0.000814      1          t   \n",
       "1                     -999.000          46.226  0.681042      0          t   \n",
       "2                     -999.000          44.251  0.715742      0          t   \n",
       "3                     -999.000          -0.000  1.660654      0          t   \n",
       "4                     -999.000           0.000  1.904263      0          t   \n",
       "5                        3.106         193.660  0.025434      0          t   \n",
       "6                       -2.767         179.877  0.000814      1          t   \n",
       "7                     -999.000          30.638  0.005721      1          t   \n",
       "8                     -999.000           0.000  1.614803      0          t   \n",
       "9                     -999.000         167.735  0.000461      1          t   \n",
       "10                    -999.000           0.000  0.701141      0          t   \n",
       "11                      -2.079         165.640  0.093659      0          t   \n",
       "12                    -999.000          93.117  0.512740      0          t   \n",
       "13                    -999.000           0.000  0.665890      0          t   \n",
       "14                    -999.000           0.000  0.655922      0          t   \n",
       "15                    -999.000          -0.000  0.005721      1          t   \n",
       "16                    -999.000          36.263  0.443598      0          t   \n",
       "17                    -999.000           0.000  0.000461      1          t   \n",
       "18                    -999.000           0.000  1.561633      0          t   \n",
       "19                    -999.000          -0.000  1.823163      0          t   \n",
       "20                    -999.000           0.000  0.670373      0          t   \n",
       "21                    -999.000           0.000  0.512740      0          t   \n",
       "22                    -999.000           0.000  1.393245      0          t   \n",
       "23                      -2.785         278.009  0.000461      1          t   \n",
       "24                    -999.000           0.000  0.774979      0          t   \n",
       "25                    -999.000          -0.000  0.512740      0          t   \n",
       "26                    -999.000          35.527  0.000461      1          t   \n",
       "27                      -0.103         214.170  0.000461      1          t   \n",
       "28                    -999.000          77.221  0.000461      1          t   \n",
       "29                      -1.467         113.252  0.094460      0          t   \n",
       "...                        ...             ...       ...    ...        ...   \n",
       "818208                -999.000           0.000  0.925626      0          u   \n",
       "818209                -999.000           0.000  1.385835      0          u   \n",
       "818210                -999.000           0.000  0.005721      1          u   \n",
       "818211                -999.000          37.489  0.512740      0          u   \n",
       "818212                -999.000          52.332  0.226870      0          u   \n",
       "818213                -999.000          -0.000  0.909680      0          u   \n",
       "818214                -999.000         126.319  0.782818      0          u   \n",
       "818215                -999.000           0.000  0.005721      1          u   \n",
       "818216                -999.000           0.000  0.636427      0          u   \n",
       "818217                -999.000          48.125  0.000461      1          u   \n",
       "818218                -999.000          -0.000  0.611755      0          u   \n",
       "818219                -999.000           0.000  0.512740      0          u   \n",
       "818220                -999.000          -0.000  0.562147      0          u   \n",
       "818221                   1.287         140.280  0.000461      1          u   \n",
       "818222                  -2.218         250.408  0.000461      1          u   \n",
       "818223                   0.832         369.304  0.226870      0          u   \n",
       "818224                -999.000          37.855  0.633648      0          u   \n",
       "818225                   1.868          90.118  0.000814      1          u   \n",
       "818226                -999.000          38.654  0.005721      1          u   \n",
       "818227                -999.000         210.299  0.005721      1          u   \n",
       "818228                -999.000           0.000  1.433869      0          u   \n",
       "818229                  -1.672         136.986  0.000461      1          u   \n",
       "818230                   2.747         320.076  0.301427      0          u   \n",
       "818231                -999.000         110.841  0.019533      0          u   \n",
       "818232                -999.000          -0.000  1.433121      0          u   \n",
       "818233                  -1.090         154.056  0.005721      1          u   \n",
       "818234                   2.893         178.856  0.000461      1          u   \n",
       "818235                -999.000          -0.000  1.189365      0          u   \n",
       "818236                -999.000          30.863  0.512740      0          u   \n",
       "818237                -999.000          -0.000  1.531213      0          u   \n",
       "\n",
       "        KaggleWeight  \n",
       "0           0.002653  \n",
       "1           2.233584  \n",
       "2           2.347389  \n",
       "3           5.446378  \n",
       "4           6.245333  \n",
       "5           0.083414  \n",
       "6           0.002653  \n",
       "7           0.018636  \n",
       "8           5.296003  \n",
       "9           0.001502  \n",
       "10          2.299504  \n",
       "11          0.307170  \n",
       "12          1.681611  \n",
       "13          2.183892  \n",
       "14          2.151199  \n",
       "15          0.018636  \n",
       "16          1.454848  \n",
       "17          0.001503  \n",
       "18          5.121624  \n",
       "19          5.979351  \n",
       "20          2.198594  \n",
       "21          1.681611  \n",
       "22          4.569368  \n",
       "23          0.001503  \n",
       "24          2.541666  \n",
       "25          1.681611  \n",
       "26          0.001503  \n",
       "27          0.001503  \n",
       "28          0.001503  \n",
       "29          0.309795  \n",
       "...              ...  \n",
       "818208     41.468615  \n",
       "818209     62.086275  \n",
       "818210      0.259892  \n",
       "818211     22.971060  \n",
       "818212     10.163918  \n",
       "818213     40.754236  \n",
       "818214     35.070702  \n",
       "818215      0.259892  \n",
       "818216     28.512309  \n",
       "818217      0.020956  \n",
       "818218     27.407016  \n",
       "818219     22.971060  \n",
       "818220     25.184532  \n",
       "818221      0.020956  \n",
       "818222      0.020956  \n",
       "818223     10.163918  \n",
       "818224     28.387819  \n",
       "818225      0.037002  \n",
       "818226      0.259892  \n",
       "818227      0.259892  \n",
       "818228     64.238228  \n",
       "818229      0.020956  \n",
       "818230     13.504126  \n",
       "818231      0.875080  \n",
       "818232     64.204716  \n",
       "818233      0.259892  \n",
       "818234      0.020956  \n",
       "818235     53.284258  \n",
       "818236     22.971060  \n",
       "818237     68.599269  \n",
       "\n",
       "[818238 rows x 35 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map y values to integers\n",
    "df['Label'] = df['Label'].map({'b':0, 's':1})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create separate arrays\n",
    "eventID = df['EventId']\n",
    "X = df.loc[:,'DER_mass_MMC':'PRI_jet_all_pt']\n",
    "y = df['Label']\n",
    "weight = df['Weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now split into testing and training samples\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test, eventID_train, event_ID_test, weight_train, weight_test = train_test_split(\n",
    "    X, y, eventID, weight, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's first look at a NN in sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.09661620\n",
      "Iteration 2, loss = 0.77360641\n",
      "Iteration 3, loss = 0.69369140\n",
      "Iteration 4, loss = 0.65115646\n",
      "Iteration 5, loss = 0.65273863\n",
      "Iteration 6, loss = 0.59829970\n",
      "Iteration 7, loss = 0.58051744\n",
      "Iteration 8, loss = 0.55886981\n",
      "Iteration 9, loss = 0.54314695\n",
      "Iteration 10, loss = 0.52709540\n",
      "Iteration 11, loss = 0.51315467\n",
      "Iteration 12, loss = 0.50276055\n",
      "Iteration 13, loss = 0.49673716\n",
      "Iteration 14, loss = 0.48118571\n",
      "Iteration 15, loss = 0.47269283\n",
      "Iteration 16, loss = 0.46676295\n",
      "Iteration 17, loss = 0.45607049\n",
      "Iteration 18, loss = 0.44819029\n",
      "Iteration 19, loss = 0.44177381\n",
      "Iteration 20, loss = 0.43835115\n",
      "Iteration 21, loss = 0.43470856\n",
      "Iteration 22, loss = 0.42708861\n",
      "Iteration 23, loss = 0.42272210\n",
      "Iteration 24, loss = 0.41844147\n",
      "Iteration 25, loss = 0.41583758\n",
      "Iteration 26, loss = 0.41298021\n",
      "Iteration 27, loss = 0.41073323\n",
      "Iteration 28, loss = 0.40745335\n",
      "Iteration 29, loss = 0.40654803\n",
      "Iteration 30, loss = 0.40497223\n",
      "Iteration 31, loss = 0.40339184\n",
      "Iteration 32, loss = 0.40132822\n",
      "Iteration 33, loss = 0.39982457\n",
      "Iteration 34, loss = 0.39892439\n",
      "Iteration 35, loss = 0.39803037\n",
      "Iteration 36, loss = 0.39775924\n",
      "Iteration 37, loss = 0.39735923\n",
      "Iteration 38, loss = 0.39615835\n",
      "Iteration 39, loss = 0.39468398\n",
      "Iteration 40, loss = 0.39469154\n",
      "Iteration 41, loss = 0.39564118\n",
      "Iteration 42, loss = 0.39430767\n",
      "Iteration 43, loss = 0.39426559\n",
      "Iteration 44, loss = 0.39359410\n",
      "Iteration 45, loss = 0.39361073\n",
      "Iteration 46, loss = 0.39332553\n",
      "Iteration 47, loss = 0.39288335\n",
      "Iteration 48, loss = 0.39288956\n",
      "Iteration 49, loss = 0.39249895\n",
      "Iteration 50, loss = 0.39254724\n",
      "Iteration 51, loss = 0.39165088\n",
      "Iteration 52, loss = 0.39164403\n",
      "Iteration 53, loss = 0.39257011\n",
      "Iteration 54, loss = 0.39095508\n",
      "Iteration 55, loss = 0.39124732\n",
      "Iteration 56, loss = 0.39067674\n",
      "Iteration 57, loss = 0.39031591\n",
      "Iteration 58, loss = 0.39081036\n",
      "Iteration 59, loss = 0.39067312\n",
      "Iteration 60, loss = 0.39015605\n",
      "Iteration 61, loss = 0.38970398\n",
      "Iteration 62, loss = 0.38965897\n",
      "Iteration 63, loss = 0.38943723\n",
      "Iteration 64, loss = 0.38966234\n",
      "Iteration 65, loss = 0.38931028\n",
      "Iteration 66, loss = 0.38940167\n",
      "Iteration 67, loss = 0.38897356\n",
      "Iteration 68, loss = 0.38872195\n",
      "Iteration 69, loss = 0.38865690\n",
      "Iteration 70, loss = 0.38861349\n",
      "Iteration 71, loss = 0.38836295\n",
      "Iteration 72, loss = 0.38813779\n",
      "Iteration 73, loss = 0.38838257\n",
      "Iteration 74, loss = 0.38848906\n",
      "Iteration 75, loss = 0.38746367\n",
      "Iteration 76, loss = 0.38767734\n",
      "Iteration 77, loss = 0.38788387\n",
      "Iteration 78, loss = 0.38814095\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and train\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.820245982690107"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kaggle competition used the approximate median segnificance (AMS), as defined below, to determine how good a solution was. The number 10, added to the background yield, is a regularization term to decrease the variance of the AMS.\n",
    "\n",
    "Note that if you do not use the full data set (i.e. you split into training and testing) you have to reweigh the inputs so that the subsample yield matches to the toal yield, which we will do below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute approximate median segnificance (AMS)\n",
    "\n",
    "def ams(s,b):\n",
    "    from math import sqrt,log\n",
    "    if b==0:\n",
    "        return 0\n",
    "\n",
    "    return sqrt(2*((s+b+10)*log(1+float(s)/(b+10))-s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7374296857662506"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try a different probability cut, not the one given by default to predict().\n",
    "# We choose the top 15%, but can optimize\n",
    "y_train_prob = mlp.predict_proba(X_train)[:, 1]\n",
    "y_test_prob = mlp.predict_proba(X_test)[:, 1]\n",
    "pcut = np.percentile(y_train_prob,85)\n",
    "pcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the probability to the original data frame\n",
    "df['Prob']=mlp.predict_proba(X)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gduckeck/anaconda3/lib/python3.5/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n",
      "/home/gduckeck/anaconda3/lib/python3.5/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff81a75fcc0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kwargs = dict(histtype='stepfilled', alpha=0.3, normed=True, bins=40)\n",
    "\n",
    "df[df.Label==0].Prob.hist(label='Background',**kwargs)\n",
    "df[df.Label==1].Prob.hist(label='Signal',**kwargs)\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's calculate the total weights (yields)\n",
    "sigall = weight.dot(y)\n",
    "backall = weight.dot(y == 0)\n",
    "\n",
    "# The training weights\n",
    "sigtrain = weight_train.dot(y_train)\n",
    "backtrain = weight_train.dot(y_train == 0)\n",
    "\n",
    "# The training weights\n",
    "sigtest = weight_test.dot(y_test)\n",
    "backtest = weight_test.dot(y_test == 0)\n",
    "\n",
    "# aside:  these can also be done by looping instead of using a dot product\n",
    "#  (Usually vectorized operations are faster for interpreted code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's look at event yields that pass our selection\n",
    "sigtrain_sel = weight_train.dot(np.multiply(y_train, y_train_prob > pcut))\n",
    "backtrain_sel = weight_train.dot(np.multiply(y_train == 0, y_train_prob > pcut))\n",
    "\n",
    "sigtest_sel = weight_test.dot(np.multiply(y_test, y_test_prob > pcut))\n",
    "backtest_sel = weight_test.dot(np.multiply(y_test == 0, y_test_prob > pcut))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected selected yields in training sample, signal = 263.8957425160544 , background = 7523.137450569208\n",
      "Corrected selected yields in test sample, signal = 263.23220559287773 , background = 7605.314126341242\n"
     ]
    }
   ],
   "source": [
    "# Now we need to correct the selected yields to be is if we used the full sample\n",
    "sigtrain_sel_corr = sigtrain_sel*sigall/sigtrain\n",
    "backtrain_sel_corr = backtrain_sel*backall/backtrain\n",
    "\n",
    "sigtest_sel_corr = sigtest_sel*sigall/sigtest\n",
    "backtest_sel_corr = backtest_sel*backall/backtest\n",
    "\n",
    "print(\"Corrected selected yields in training sample, signal =\", sigtrain_sel_corr, \", background =\",backtrain_sel_corr)\n",
    "print(\"Corrected selected yields in test sample, signal =\", sigtest_sel_corr, \", background =\",backtest_sel_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMS of training sample 3.1082926036692693\n",
      "AMS of test sample 3.034135675570529\n"
     ]
    }
   ],
   "source": [
    "print(\"AMS of training sample\", ams(sigtrain_sel_corr,backtrain_sel_corr))\n",
    "print(\"AMS of test sample\", ams(sigtest_sel_corr,backtest_sel_corr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did we do? Worse than the BDT from yesterday.\n",
    "![Comparison with submissions](data/tr150908_davidRousseau_TMVAFuture_HiggsML.001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks are quite sensitive to feature scaling, so let's try to scale the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff819649f98>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaQAAAEECAYAAABnUEDbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFcVJREFUeJzt3X+QXeV93/H3B1EZhBFa/COtKUHGJFUwzTgZeabQPxibOlgQvB3HhLjjNMQTN8zUsRs6bgRBZU3qWnjGxozVDo4zGbfJuAzGJFvAsgbZAdNgN0ZN3dpCmNqRwQVcE6+sEQILi6d/nLPo6Oqu9mp1d++zV+/XzJnVfc73fPfuo9397Lnnx00pBUmSRu2kUT8BSZLAQJIkVcJAkiRVwUCSJFXBQJIkVcFAkiRVwUCSJFXBQJIkVcFAkiRV4eRRP4Hl5JWvfGVZu3btgrbds2cPa9asGe4TWuack/6clyM5J/0tl3nZsWPHM6WUV81XZyAdg7Vr1/Lwww8vaNvp6WkmJyeH/IyWN+ekP+flSM5Jf8tlXpJ8d5A6X7KTJFXBQJIkVcFAkiRVwUCSJFXBQJIkVcFAkiRVwUCSJFXBQJIkVcELY6UxsHbjvX3Hd2++fImfibRw7iFJkqpgIEmSqmAgSZKqYCBJkqpgIEmSqmAgSZKqYCBJkqpgIEmSqmAgSZKqYCBJkqpgIEmSqmAgSZKqYCBJkqpgIEmSqmAgSZKqYCBJkqowbyAluTLJf03yf5PsS7IjyTv71L0nyWNJnm9rLulTc1aSP2v7PJNkS5JVo+4lSRq9QfaQrgX2Ab8LvA34C+AzSX5ntiDJrwG3Af8Z2AB8E7gnyQWdmpOBbcA5wFXA+4ErgT/sfrKl7iVJqsMgb2F+RSnlmc7jLyV5DU1QfaId+yDwn0opfwCQ5AHgF4CNwLvamiuBnwPOK6X8TVv3AnB7kg+WUh4bUS9JUgXm3UPqCaNZfw28GiDJucDPAnd0tnkR+CzNXsmsDcDXZgOk9efAAeCtI+wlSarAQk9quAjY2f57XftxV0/NI8CZSV7VqTusppRyAPh2p8coekmSKjDIS3aHaU8KmATe3Q5NtB/39JTOdNb/oP3YWzNbN9GpXepeR5VkCrgRYGJigunp6fk2mdPxbDuunJP+jnVebr1wOH1qNk5fyzCN07wcUyAlWQt8BpgupXy6Z3XpLe8z3lszW9c7vtS95lRKmQKmANavX18mJycH2ewI09PTLHTbceWc9LeQeVm78d6+47s3Xz6MpzRyfq/0N27zMvBLdknOBLYCj3P4CQGzexxrejaZfbynU9dbM1vXrVnqXpKkCgwUSO31PfcAK4HLSynPdlbPHqNZ17PZOuCHpZQfdOoOq0myEji302MUvSRJFRjkwtiTac5M+xlgQynl/3XXl1K+A3yL5lTs2W1Oah9v7ZRuBd6Y5JzO2NuAlwFfGGEvSVIFBjmG9B+By2guPj0zyT/qrPvrUsqPaY6x/GmS3cBfAr9BE2D/rFN7J/D7wF1JNgFnALcAn+lcN8QIekmSKjBIIP1S+/HWPuteC+wupfyXJC8Hfg/YRHNHhF8upXxjtrCU8kKStwJbaK4N+jFwO/CBbsOl7iVJqsO8gVRKWTtIo1LKp4BPzVPzPeCf1tZLkjR63u1bklQFA0mSVAUDSZJUBQNJklQFA0mSVAUDSZJUBQNJklQFA0mSVAUDSZJUBQNJklQFA0mSVAUDSZJUBQNJklQFA0mSVAUDSZJUBQNJklQFA0mSVAUDSZJUBQNJklQFA0mSVAUDSZJUBQNJklQFA0mSVAUDSZJUBQNJklQFA0mSVAUDSZJUBQNJklQFA0mSVAUDSZJUBQNJklQFA0mSVAUDSZJUhYECKcl5ST6Z5OtJDia5v0/N7iSlZ3m6T935Sb6YZH+SJ5PclGRFT02SXJ/kiSTPJflykjcsZi9J0midPGDd64HLgK8CK49S9xngE53HB7ork0wA24GdwCTwOuCjNMF4Q6d0I7AJ+ACwC7gW2J7kglLK08PuJUkavUED6e5SyjRAkjuBV85R91Qp5atH6XMNcCrw9lLKXuC+JKuBqSQfKaXsTXIKTYh8uJSypf2cXwF2A+/lUNgMs5ckacQGesmulPLikD7fBmBbGyCzbqcJlovbxxcBq4E7Op//WeDudvvF6CVJGrFhn9Tw7iQHkvwoyZ1JzulZv47mZbOXlFIeB/a362ZrDgKP9Wz7SKdm2L0kSSM26Et2g5imOcb0PeDngBuBB5P8w1LKj9qaCWBPn21n2nWzNftKKQf71KxKsrKUcmDIvSRJIza0QCqlvL/z8MEkDwH/E/hN4OPd0j6bp2d8rpredcPs1VeSKZpwZWJigunp6fk2mdPxbDuunJP+jnVebr1wOH1qNk5fyzCN07wMcw/pMKWUbyR5FPjFzvAMsKZP+Rkc2tuZAU5PsqJnz2YNsL+U8sIi9Dra1zEFTAGsX7++TE5OzrdJX9PT0yx023HlnPS3kHlZu/HevuO7N18+jKc0cn6v9Ddu87IUF8Z290J20XPsJsnZwGkcOh60C1gBnNfTp/eY0TB7SZJGbNECKckFwD8AdnSGtwKXJjm9M3YV8BzwQPv4IWAvcGWn1yrginb7xeglSRqxgV6ya3+JX9Y+PAtYneQd7ePPA28C3gXcAzxJswdyA/A48OlOq9uA9wF3JbkZOJfm5bCPzZ6+XUp5PslmYFOSGQ5dzHoSh190O8xekqQRG/QY0quBz/aMzT5+LfBEW/NxmuMzfwt8Abi+e51QKWUmySXAFpprgfYAt9Aeo+nYTBMa1wGvAB4G3lJK+f5i9JIkjd5AgVRK2c2hM9PmcsmAvXYCb56npgAfapcl6SVJGi3v9i1JqoKBJEmqgoEkSaqCgSRJqoKBJEmqgoEkSaqCgSRJqoKBJEmqgoEkSaqCgSRJqoKBJEmqwqK9QZ+k4ZvrjfikceAekiSpCgaSJKkKBpIkqQoGkiSpCgaSJKkKBpIkqQoGkiSpCgaSJKkKBpIkqQoGkiSpCgaSJKkKBpIkqQoGkiSpCgaSJKkKBpIkqQoGkiSpCgaSJKkKBpIkqQoGkiSpCgaSJKkKBpIkqQoGkiSpCgMFUpLzknwyydeTHExyf5+aJLk+yRNJnkvy5SRv6FN3fpIvJtmf5MkkNyVZMepekqTRGnQP6fXAZcC32qWfjcAm4GbgCmAfsD3J350tSDIBbAcKMAncBPxr4IOj7CVJGr1BA+nuUsrZpZQrgW/2rkxyCs0v/g+XUraUUrYDV9KExXs7pdcApwJvL6XcV0q5jSZArk2yeoS9JEkjNlAglVJenKfkImA1cEdnm2eBu4ENnboNwLZSyt7O2O00wXLxCHtJkkZsWCc1rAMOAo/1jD/SruvW7eoWlFIeB/Z36kbRS5I0YicPqc8EsK+UcrBnfAZYlWRlKeVAW7enz/Yz7bpR9ZpTkingRoCJiQmmp6ePVn5Ux7PtuHJO+ptrXm69cDh9lqNx+lqGaZzmZViBBM1xmV7ps26uukFqFrNXX6WUKWAKYP369WVycnK+Tfqanp5moduOK+ekv6PNy9qN9x5Tr92bLx/GUxo5v1f6G7d5GdZLdjPA6b2nXANrgP2llBc6dWv6bH8Gh/Z2RtFLkjRiwwqkXcAK4Lye8d7jPLvoOXaT5GzgtE7dKHpJkkZsWIH0ELCX5pRqAJKsornuZ2unbitwaZLTO2NXAc8BD4ywlyRpxAY6htT+Er+sfXgWsDrJO9rHny+l7E+yGdiUZIZm7+NamsD7RKfVbcD7gLuS3AycS3N85mOzp2+XUp4fQS9J0ogNelLDq4HP9ozNPn4tsBvYTPOL/jrgFcDDwFtKKd+f3aCUMpPkEmALzbVAe4BbaE8a6FjSXpKk0RsokEopuzl0ZtpcNQX4ULscrW4n8ObaekmSRsu7fUuSqmAgSZKqYCBJkqpgIEmSqmAgSZKqYCBJkqpgIEmSqjDMu31rHv3u1Dwud2OWpOPlHpIkqQoGkiSpCgaSJKkKBpIkqQoGkiSpCgaSJKkKBpIkqQoGkiSpCgaSJKkKBpIkqQoGkiSpCgaSJKkKBpIkqQoGkiSpCgaSJKkKBpIkqQoGkiSpCgaSJKkKvoW5NMbWbry37/juzZcv8TOR5ucekiSpCgaSJKkKBpIkqQoGkiSpCgaSJKkKBpIkqQpDC6QkVycpfZZrOjVJcn2SJ5I8l+TLSd7Qp9f5Sb6YZH+SJ5PclGRFT83QekmSRm8xrkN6M/Bc5/F3Ov/eCGwCPgDsAq4Ftie5oJTyNECSCWA7sBOYBF4HfJQmPG9YpF6SpBFbjED6WillX+9gklNoQuTDpZQt7dhXgN3AezkUENcApwJvL6XsBe5LshqYSvKRUsreYfYa/pcvSVqIpTyGdBGwGrhjdqCU8ixwN7ChU7cB2NYTFrfTBMvFi9BLklSBxQikbyf5SZJHk/x2Z3wdcBB4rKf+kXZdt25Xt6CU8jiwv1M3zF6SpAoM8yW7p2iO6fwVsAJ4J3BbklWllFuACWBfKeVgz3YzwKokK0spB9q6PX36z7TrGHKvo0oyBdwIMDExwfT09CCb9XXrhT85Yux4+o2DE/3rn8tc83LrhYvbv2bL8TkvhXGal6EFUillG7CtM7Q1ycuAG5LcOlvWZ9P0WTdX3SA1C+k1p1LKFDAFsH79+jI5OTnIZkeYnp7m/V85crpP5JtcTk9Ps9D5HGdHm5e5bpZ6rJbb953fK/2N27ws9jGkO4EzgbU0eyWn9znleg2wv5TyQvt4ph3rdQaH9naG2UuSVIGlOqmh0BzLWQGc17Ou9zjPLnqO7yQ5GzitUzfMXpKkCix2IP0K8AzwXeAhYC9w5ezKJKuAK4CtnW22ApcmOb0zdhXNtU0PtI+H2UuSVIGhHUNK8jmaExr+F83ey1Xt8r5SyovA80k2A5uSzHDoYtaTgE90Wt0GvA+4K8nNwLk0x3A+Nnv6dillaL0kSXUY5ll2jwLvBs6mOWlgJ/DPSyl/0qnZTBMa1wGvAB4G3lJK+f5sQSllJsklwBaa64r2ALfQnliwSL0kSSM2zLPsrgeun6emAB9ql6PV7aS5BdGS9JIkjZ53+5YkVcFAkiRVwUCSJFXBQJIkVcFAkiRVwUCSJFXBQJIkVcFAkiRVwUCSJFXBQJIkVcFAkiRVwUCSJFXBQJIkVcFAkiRVwUCSJFXBQJIkVcFAkiRVwUCSJFXBQJIkVcFAkiRVwUCSJFXBQJIkVcFAkiRV4eRRPwFJS2/txnv7ju/efPkSPxPpEPeQJElVMJAkSVUwkCRJVfAYklShuY7xSOPMPSRJUhUMJElSFQwkSVIVPIYk6SVHO3blNUpabO4hSZKqcEIEUpLzk3wxyf4kTya5KcmKUT8vSdIhY/+SXZIJYDuwE5gEXgd8lCaMbxjhU5OWFW83pMU29oEEXAOcCry9lLIXuC/JamAqyUfaMUnSiJ0IgbQB2NYTPLcDNwMXA3eP5FlJY8I9Jw3LiRBI64AvdQdKKY8n2d+uM5CkRXCsd5swwHQiBNIEsKfP+Ey77qiSTAE3tg/3J3lkgc/jNcCTR/S/eYHdxkPfOdGJOS/z/CyckHMygOUyL+cMUnQiBBJA6TOWOcYP37CUKWDqeJ9AklJKec3x9hknzkl/zsuRnJP+xm1eToTTvmeANX3Gz6D/npMkaQROhEDaRXOs6CVJzgZOa9dJkipwIgTSVuDSJKd3xq4CngMeWMLn8cEl/FzLhXPSn/NyJOekv7Gal5Qy72GUZa29MHYn8A2aU73PBT4GfLyU4oWxklSJsQ8kaG4dBGwBLqQ5bvRHwFQp5eBIn5gk6SUnRCBJkup3IhxDkiQtAwaSJKkKBpIkqQoGkiSpCgbSAiW5KsldSZ5KUpJcPUfdWUn+LMm+JM8k2ZJkVZ+69yR5LMnzSXYkuWShvWqS5P52fnqXU3rqhjZPy9GJ9CaSSa6e43vimk5Nklyf5IkkzyX5cpI39Om1LOctyXlJPpnk60kOJrm/T83Q5mDQXqN2otzLbjG8A1gL3AP8Vr+CJCcD24ADNBfjrqG5BmoN8K5O3a8Bt9HcM++/Ab8J3JPkjaWUbxxLr0r9BXB9z9iPZ/8xzHlajk7gN5F8M80F6rO+0/n3RmAT8AGaO6pcC2xPckEp5WlY9vP2euAy4KvAyjlqhjkH8/aqQinFZQELcFL78eU0N2m9uk/NO4GDwGs7Y78KvAj8TGfsUeCPu72B/w386bH2qm0B7gfunKdmaPO0HBfgOpp7Lq7ujP0bYH93bFwW4Or2Z+blc6w/BfgR8G87Y6cBPwD+3TjM2+zvj/bfdwL3L9YcDNqrhsWX7BaolPLiAGUbgK+VUv6mM/bnNHsCbwVIci7ws8AdPb0/224/cK9lbJjztBzN9SaSp9K8ieSJ5iJgNYf/Xz9L895lvT8Ty3LeBvj9Mcw5GLTXyBlIi2sdPTdwLaUcAL7NoRu+zn7svdHrI8CZSV51DL1q9Uvt69v7k2xL8vM964c5T8tRv6//cZq/cmv/vz0e307ykySPJvntzvg6mj3mx3rqH+Hw+RjneRvmHAzaa+QMpMU1yJsDzn7srZvpWX9cbzQ4Qg8A7wcuBf4F8NPAg0nWdmqGOU/L0XL9v12op2iOZ/w6cAXw34Hbkvxuu34C2FeOvLXXDLAqycpO3bjO2zDnYNBeI+dJDa0kZwB/b766UsqxvmXFoG8O2Ps4fcYX/EaDw3Ks81RKubEz/GCS7TR/0f2rdnlpk36frs/4IPO0HI38/3aplFK20ZzEMmtrkpcBNyS5dbasz6ZV/kwsomHOwaC9RspAOuRK4FMD1GX+kpfM9eaAazj0V81MZ+xHPTX01M3Xaykc1zyVUp5O8pfAL3aGhzlPy5FvItkc2P9VmjNXZ4DTk6zo+at+DbC/lPJC+3ic522YczBor5HzJbtWKeWPSimZbznGtv3eHHAlzVtg7OrU0FvXPv5hKeUHx9Br0Q1xnrp/lQ1znpYj30TykELzNa8AzutZ13u8ZJznbZhzMGivkTOQFtdW4I1JzumMvQ14GfAFgFLKd4Bv0ex5AJDkpPbx1mPptRwk+SngHwM7OsPDnKflqJY3kRylXwGeAb4LPATs5fD/61U0x5t6fybGdd6GOQeD9hq9UZ93vlwX4Hyai2PfRfNX3Zb28cWdmr9D88aAO2gugnsn8DQ9181w6DqcG4A3AZ+m+Ya64Fh71bQAPw/cS3PdyZuA36D5i+yHwE8vxjwtx4XmoPNTwH3AP6E5+WMflV0jMsSv93PA79GccvzLwJ+0P0O/06m5juZMsX8JXNJ+Hz0D/NQ4zBuwqv198Q7gK8A3O49XDXsOBulVwzLyJ7BcF5q7BZQ+y/09dX+f5pqafcDfAv9h9huup+49wP+huYPB/wAu6VMzUK9aFuAs4PPtD8yB9jl/Dli30K9tkHlajgvNHzhfagP2KeAPgBWjfl6L9LX+e5qLnPe3X+8O4Nd7agL8PvC9tuZB4BfGZd5ojpX1+/1RgLXDnoNBe4168Q36JElV8BiSJKkKBpIkqQoGkiSpCgaSJKkKBpIkqQoGkiSpCgaSJKkKBpIkqQr/H5J4pG+snwfJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train.DER_mass_MMC.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a=plt.hist(X_train_scaled[:,0],bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.40567153\n",
      "Iteration 2, loss = 0.37743384\n",
      "Iteration 3, loss = 0.37171010\n",
      "Iteration 4, loss = 0.36869241\n",
      "Iteration 5, loss = 0.36671551\n",
      "Iteration 6, loss = 0.36552037\n",
      "Iteration 7, loss = 0.36464791\n",
      "Iteration 8, loss = 0.36379843\n",
      "Iteration 9, loss = 0.36321345\n",
      "Iteration 10, loss = 0.36255538\n",
      "Iteration 11, loss = 0.36224304\n",
      "Iteration 12, loss = 0.36185050\n",
      "Iteration 13, loss = 0.36155966\n",
      "Iteration 14, loss = 0.36112230\n",
      "Iteration 15, loss = 0.36105074\n",
      "Iteration 16, loss = 0.36069082\n",
      "Iteration 17, loss = 0.36051894\n",
      "Iteration 18, loss = 0.36017131\n",
      "Iteration 19, loss = 0.36015432\n",
      "Iteration 20, loss = 0.35996604\n",
      "Iteration 21, loss = 0.35989021\n",
      "Iteration 22, loss = 0.35958988\n",
      "Iteration 23, loss = 0.35958384\n",
      "Iteration 24, loss = 0.35942606\n",
      "Iteration 25, loss = 0.35913098\n",
      "Iteration 26, loss = 0.35924665\n",
      "Iteration 27, loss = 0.35907309\n",
      "Iteration 28, loss = 0.35900896\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and train a new network\n",
    "mlp_scaled = MLPClassifier(verbose=True)\n",
    "mlp_scaled.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8371484969576215"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_scaled.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a different probability cut, not the one given by default to predict().\n",
    "# We choose the top 15%, but can optimize\n",
    "y_train_prob_scaled = mlp_scaled.predict_proba(X_train_scaled)[:, 1]\n",
    "y_test_prob_scaled = mlp_scaled.predict_proba(X_test_scaled)[:, 1]\n",
    "pcut_scaled = np.percentile(y_train_prob_scaled,85)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's look at event yields that pass our selection\n",
    "sigtrain_sel_scaled = weight_train.dot(np.multiply(y_train, y_train_prob_scaled > pcut_scaled))\n",
    "backtrain_sel_scaled = weight_train.dot(np.multiply(y_train == 0, y_train_prob_scaled > pcut_scaled))\n",
    "\n",
    "sigtest_sel_scaled = weight_test.dot(np.multiply(y_test, y_test_prob_scaled > pcut_scaled))\n",
    "backtest_sel_scaled = weight_test.dot(np.multiply(y_test == 0, y_test_prob_scaled > pcut_scaled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected selected yields in training sample, signal = 230.2290305975397 , background = 4207.713837982401\n",
      "Corrected selected yields in test sample, signal = 228.54406510620893 , background = 4519.307063997606\n"
     ]
    }
   ],
   "source": [
    "# Now we need to correct the selected yields to be is if we used the full sample\n",
    "sigtrain_sel_scaled_corr = sigtrain_sel_scaled*sigall/sigtrain\n",
    "backtrain_sel_scaled_corr = backtrain_sel_scaled*backall/backtrain\n",
    "\n",
    "sigtest_sel_scaled_corr = sigtest_sel_scaled*sigall/sigtest\n",
    "backtest_sel_scaled_corr = backtest_sel_scaled*backall/backtest\n",
    "\n",
    "print(\"Corrected selected yields in training sample, signal =\", sigtrain_sel_scaled_corr, \", background =\",backtrain_sel_scaled_corr)\n",
    "print(\"Corrected selected yields in test sample, signal =\", sigtest_sel_scaled_corr, \", background =\",backtest_sel_scaled_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMS of training sample 3.513503562990113\n",
      "AMS of test sample 3.3679188562698963\n"
     ]
    }
   ],
   "source": [
    "print(\"AMS of training sample\", ams(sigtrain_sel_scaled_corr,backtrain_sel_scaled_corr))\n",
    "print(\"AMS of test sample\", ams(sigtest_sel_scaled_corr,backtest_sel_scaled_corr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We improved somewhat.\n",
    "\n",
    "SciKit Learn has simple NNs, but if you want to do deep NNs, or train on GPUs, you probalby want to use something like Keras instead. Let's try to create a simple NN using Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gduckeck/anaconda3/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape=(30,), kernel_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.9909186536998906, 1: 1182.3150708555781}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight = {0: y_train.shape[0]/backtrain, 1:y_train.shape[0]/sigtrain}\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "548219/548219 [==============================] - 14s 26us/step - loss: 0.4015 - acc: 0.8225\n",
      "Epoch 2/5\n",
      "548219/548219 [==============================] - 14s 25us/step - loss: 0.3824 - acc: 0.8317\n",
      "Epoch 3/5\n",
      "548219/548219 [==============================] - 14s 26us/step - loss: 0.3771 - acc: 0.8339\n",
      "Epoch 4/5\n",
      "548219/548219 [==============================] - 14s 26us/step - loss: 0.3749 - acc: 0.8345\n",
      "Epoch 5/5\n",
      "548219/548219 [==============================] - 14s 25us/step - loss: 0.3739 - acc: 0.8348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff7c816ecf8>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.fit(X_train_scaled, y_train, epochs=5, batch_size=128, sample_weight=weight_train)\n",
    "model.fit(X_train_scaled, y_train, epochs=5, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a different probability cut, not the one given by default to predict().\n",
    "# We choose the top 15%, but can optimize\n",
    "y_train_prob_keras = model.predict(X_train_scaled)[:, 0]\n",
    "y_test_prob_keras = model.predict(X_test_scaled)[:, 0]\n",
    "pcut_keras = np.percentile(y_train_prob_keras,85)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8595679 , 0.1556208 , 0.03185635, ..., 0.21461262, 0.08116557,\n",
       "       0.02808595], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_prob_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's look at event yields that pass our selection\n",
    "sigtrain_sel_keras = weight_train.dot(np.multiply(y_train, y_train_prob_keras > pcut_keras))\n",
    "backtrain_sel_keras = weight_train.dot(np.multiply(y_train == 0, y_train_prob_keras > pcut_keras))\n",
    "\n",
    "sigtest_sel_keras = weight_test.dot(np.multiply(y_test, y_test_prob_keras > pcut_keras))\n",
    "backtest_sel_keras = weight_test.dot(np.multiply(y_test == 0, y_test_prob_keras > pcut_keras))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected selected yields in training sample, signal = 235.8955925518231 , background = 4809.411277425625\n",
      "Corrected selected yields in test sample, signal = 235.68968494766844 , background = 5045.200749907617\n"
     ]
    }
   ],
   "source": [
    "# Now we need to correct the selected yields to be is if we used the full sample\n",
    "sigtrain_sel_keras_corr = sigtrain_sel_keras*sigall/sigtrain\n",
    "backtrain_sel_keras_corr = backtrain_sel_keras*backall/backtrain\n",
    "\n",
    "sigtest_sel_keras_corr = sigtest_sel_keras*sigall/sigtest\n",
    "backtest_sel_keras_corr = backtest_sel_keras*backall/backtest\n",
    "\n",
    "print(\"Corrected selected yields in training sample, signal =\", sigtrain_sel_keras_corr, \", background =\",backtrain_sel_keras_corr)\n",
    "print(\"Corrected selected yields in test sample, signal =\", sigtest_sel_keras_corr, \", background =\",backtest_sel_keras_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMS of training sample 3.370825980185291\n",
      "AMS of test sample 3.2896364370361337\n"
     ]
    }
   ],
   "source": [
    "print(\"AMS of training sample\", ams(sigtrain_sel_keras_corr,backtrain_sel_keras_corr))\n",
    "print(\"AMS of test sample\", ams(sigtest_sel_keras_corr,backtest_sel_keras_corr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only made a single layer NN in Keras. However, you can easily change the structure of the network. As an assignment, try adding an extra hidden layer and changing the number of neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few things we can easily vary: number of hidden layers, the activation function, the regularization ($\\alpha$). Let's go back to MLPClassifer (scaled) and play with some of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.38851825\n",
      "Iteration 2, loss = 0.37135889\n",
      "Iteration 3, loss = 0.36824245\n",
      "Iteration 4, loss = 0.36636816\n",
      "Iteration 5, loss = 0.36511768\n",
      "Iteration 6, loss = 0.36414832\n",
      "Iteration 7, loss = 0.36350149\n",
      "Iteration 8, loss = 0.36293814\n",
      "Iteration 9, loss = 0.36246490\n",
      "Iteration 10, loss = 0.36216998\n",
      "Iteration 11, loss = 0.36172783\n",
      "Iteration 12, loss = 0.36141198\n",
      "Iteration 13, loss = 0.36130314\n",
      "Iteration 14, loss = 0.36122711\n",
      "Iteration 15, loss = 0.36096829\n",
      "Iteration 16, loss = 0.36066835\n",
      "Iteration 17, loss = 0.36059962\n",
      "Iteration 18, loss = 0.36042706\n",
      "Iteration 19, loss = 0.36032510\n",
      "Iteration 20, loss = 0.36017700\n",
      "Iteration 21, loss = 0.36030321\n",
      "Iteration 22, loss = 0.36008982\n",
      "Iteration 23, loss = 0.35995420\n",
      "Iteration 24, loss = 0.35994922\n",
      "Iteration 25, loss = 0.35979653\n",
      "Iteration 26, loss = 0.35983207\n",
      "Iteration 27, loss = 0.35955467\n",
      "Iteration 28, loss = 0.35961139\n",
      "Iteration 29, loss = 0.35960521\n",
      "Iteration 30, loss = 0.35954858\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100, 100), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_play = MLPClassifier(activation='relu', hidden_layer_sizes=(100,100), alpha=0.01, verbose=True)\n",
    "mlp_play.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8387150533851322"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_play.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a different probability cut, not the one given by default to predict().\n",
    "# We choose the top 15%, but can optimize\n",
    "y_train_prob_play = mlp_play.predict_proba(X_train_scaled)[:, 1]\n",
    "y_test_prob_play = mlp_play.predict_proba(X_test_scaled)[:, 1]\n",
    "pcut_play = np.percentile(y_train_prob_scaled,85)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's look at event yields that pass our selection\n",
    "sigtrain_sel_play = weight_train.dot(np.multiply(y_train, y_train_prob_play > pcut_play))\n",
    "backtrain_sel_play = weight_train.dot(np.multiply(y_train == 0, y_train_prob_play > pcut_play))\n",
    "\n",
    "sigtest_sel_play = weight_test.dot(np.multiply(y_test, y_test_prob_play > pcut_play))\n",
    "backtest_sel_play = weight_test.dot(np.multiply(y_test == 0, y_test_prob_play > pcut_play))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected selected yields in training sample, signal = 220.86158731141674 , background = 3707.4475567125946\n",
      "Corrected selected yields in test sample, signal = 221.6984568910555 , background = 4055.177908467606\n"
     ]
    }
   ],
   "source": [
    "# Now we need to correct the selected yields to be is if we used the full sample\n",
    "sigtrain_sel_play_corr = sigtrain_sel_play*sigall/sigtrain\n",
    "backtrain_sel_play_corr = backtrain_sel_play*backall/backtrain\n",
    "\n",
    "sigtest_sel_play_corr = sigtest_sel_play*sigall/sigtest\n",
    "backtest_sel_play_corr = backtest_sel_play*backall/backtest\n",
    "\n",
    "print(\"Corrected selected yields in training sample, signal =\", sigtrain_sel_play_corr, \", background =\",backtrain_sel_play_corr)\n",
    "print(\"Corrected selected yields in test sample, signal =\", sigtest_sel_play_corr, \", background =\",backtest_sel_play_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMS of training sample 3.5874019356326388\n",
      "AMS of test sample 3.4462380226116034\n"
     ]
    }
   ],
   "source": [
    "print(\"AMS of training sample\", ams(sigtrain_sel_play_corr,backtrain_sel_play_corr))\n",
    "print(\"AMS of test sample\", ams(sigtest_sel_play_corr,backtest_sel_play_corr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problems (can do with either MLPClassifier or Keras):\n",
    "1. Vary the structure of the tree (number of hidden layers, number of neurons)\n",
    "1. Vary the activation. (In Keras can do it per layer, in MLPClassifier only for all)\n",
    "1. Vary the regularization. May have to do this as the structure changes.\n",
    "1. Try using derivied variables only or primary variables only.\n",
    "1. Missing data is represented by -999 before scaling. Is there a better value to use in the training?\n",
    "1. Try using the event weights to better match the background and signal shapes in the training. Note, though, that you should still treat background and signal separately; don't scale the signal down by the weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [anaconda3]",
   "language": "python",
   "name": "Python [anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
